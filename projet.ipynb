{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b4a860a-567a-4e0b-91fa-64098277135a",
   "metadata": {},
   "source": [
    "# Projet 1 — Classification et compréhension automatique de documents éducatifs avec BERT\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Ce notebook implémente un pipeline complet de **compréhension de lecture automatique** basé sur des modèles de type **BERT**, appliqué au dataset **RACE (Reading Comprehension Dataset)**.\n",
    "\n",
    "L'approche retenue ici est **la classification multi-choix**, plus simple et parfaitement adaptée au format QCM du corpus RACE.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e7f70-bb64-4466-84b3-688d559a2db4",
   "metadata": {},
   "source": [
    "## 2. Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9fedd3-4d3b-4fdc-b637-3c614ca608ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariux/anaconda3/envs/mon_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForMultipleChoice,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2447450a-f89f-46dd-8146-69e8dd44f620",
   "metadata": {},
   "source": [
    "## 3. Chargement et analyse du dataset RACE\n",
    "\n",
    "### 3.1 Structure attendue\n",
    "\n",
    "```\n",
    "RACE/\n",
    " ├── train/\n",
    " │    ├── high/\n",
    " │    └── middle/\n",
    " ├── dev/\n",
    " └── test/\n",
    "```\n",
    "\n",
    "### 3.2 Fonction de chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187ef222-eacb-434b-8e2c-09a2f570c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_race_data(path):\n",
    "    data = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                    sample = json.load(f)\n",
    "                    for i in range(len(sample['questions'])):\n",
    "                        data.append({\n",
    "                            'article': sample['article'],\n",
    "                            'question': sample['questions'][i],\n",
    "                            'options': sample['options'][i],\n",
    "                            'answer': sample['answers'][i]\n",
    "                        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa43a9a-e063-485c-ad5e-de7be3ced032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples : 87866\n",
      "Dev samples   : 4887\n"
     ]
    }
   ],
   "source": [
    "train_data = load_race_data('RACE/train')\n",
    "dev_data   = load_race_data('RACE/dev')\n",
    "\n",
    "print(f\"Train samples : {len(train_data)}\")\n",
    "print(f\"Dev samples   : {len(dev_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43189e2d-3577-43d2-91d7-35d1920bbd4f",
   "metadata": {},
   "source": [
    "## 4. Prétraitement et tokenisation\n",
    "\n",
    "### 4.1 Initialisation du tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97cd4c06-5557-42ae-b82b-11900339b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca732d-dabe-402c-b28a-bc80f25fdcb1",
   "metadata": {},
   "source": [
    "### 4.2 Dataset PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be27651-7df2-4e8f-82fd-cf73517dc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RACE_Dataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        inputs = []\n",
    "\n",
    "        for option in item['options']:\n",
    "            encoded = self.tokenizer(\n",
    "                item['article'],\n",
    "                item['question'] + ' ' + option,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_len,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            inputs.append({\n",
    "                'input_ids': encoded['input_ids'].squeeze(),\n",
    "                'attention_mask': encoded['attention_mask'].squeeze()\n",
    "            })\n",
    "\n",
    "        label = ord(item['answer']) - ord('A')\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.stack([x['input_ids'] for x in inputs]),\n",
    "            'attention_mask': torch.stack([x['attention_mask'] for x in inputs]),\n",
    "            'labels': torch.tensor(label)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0748dcee-f294-4e96-955f-6b13396d878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RACE_Dataset(train_data, tokenizer)\n",
    "dev_dataset   = RACE_Dataset(dev_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "dev_loader   = DataLoader(dev_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d084aff-cbaa-4aad-841c-6007c7b056cf",
   "metadata": {},
   "source": [
    "## 5. Modèle BERT pour QCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da46a81-0fce-4a95-8917-55a63cf9f33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMultipleChoice(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMultipleChoice.from_pretrained('bert-base-uncased')\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ccdadf-db7e-44fb-8952-3ef9c2b9c10c",
   "metadata": {},
   "source": [
    "## 6. Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12dcaeb2-121c-4ae6-b7ff-bd2c57b04dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 2\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e5a670-66f8-4fee-bbc8-3172a11e0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'].to(device),\n",
    "            attention_mask=batch['attention_mask'].to(device),\n",
    "            labels=batch['labels'].to(device)\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abfbd3-d338-4ca3-97a0-8e54b9882095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21967 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    loss = train_epoch(model, train_loader)\n",
    "    print(f\"Epoch {epoch+1} | Loss : {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88132117-f942-4273-91fa-40a7e1ce5e08",
   "metadata": {},
   "source": [
    "## 7. Évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a5783-7453-4ada-ac0a-0f3f08a690e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'].to(device),\n",
    "                attention_mask=batch['attention_mask'].to(device)\n",
    "            )\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            preds.extend(predictions.cpu().numpy())\n",
    "            labels.extend(batch['labels'].numpy())\n",
    "\n",
    "    return accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acef653-6edb-4a5e-992a-9c8453e10b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = evaluate(model, dev_loader)\n",
    "print(f\"Accuracy validation : {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4282f5-8ec6-4adc-8c29-5623273646bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Analyse des résultats\n",
    "\n",
    "* Les questions factuelles courtes sont mieux traitées\n",
    "* Les longs passages dégradent la performance (limite 512 tokens)\n",
    "* Les questions nécessitant une inférence implicite restent difficiles\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Conclusion\n",
    "\n",
    "Ce projet démontre l'efficacité de **BERT pour la compréhension de lecture éducative**, tout en mettant en évidence ses limites sur des textes longs et complexes.\n",
    "\n",
    "Des améliorations possibles incluent :\n",
    "\n",
    "* RoBERTa ou Longformer\n",
    "* Fine-tuning plus long\n",
    "* Approche Question-Answering extractive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e0402-7821-42e7-9789-1bb671245509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mon_env)",
   "language": "python",
   "name": "mon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
